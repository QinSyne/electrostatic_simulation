# 第三课：并行算法设计 (Parallel Algorithms)

## 1. 揭晓答案：你的猜想可能错了

答案可能会让你大吃一惊：**对于你的 `solver.py` 中的加法操作，NumPy 通常只使用 1 个核心。**

### 为什么？

虽然你的 CPU 有 8 个核心，但 NumPy 的**逐元素操作**（Element-wise operations，如 `A + B`）在大多数标准实现中是**单线程**的。
- 它利用了 **SIMD**（单核内的向量化），所以比纯 Python 循环快。
- 但它并没有自动把任务分配给 8 个核心（多线程）。

**只有当你进行矩阵乘法 (`np.dot`) 或线性代数求解 (`np.linalg.solve`) 时，NumPy 才会调用底层的 BLAS 库（如 OpenBLAS 或 MKL），这时你才会看到 8 个核心全部跑满。**

这就是为什么我们需要学习**并行算法设计**——如果我们想利用那剩下的 7 个核心，我们必须显式地告诉计算机如何“分工”。

---

## 2. 核心难题：数据依赖 (Data Dependency)

要让多个核心一起工作，最大的障碍是**数据依赖**。

### 雅可比迭代 (Jacobi) - 容易并行
回顾你的代码：
```python
V_new[i, j] = 0.25 * (V_old[i-1, j] + V_old[i+1, j] + ...)
```
这里计算 `V_new` 只需要 `V_old`。
- 核心 A 计算左半边，读取 `V_old`。
- 核心 B 计算右半边，读取 `V_old`。
- **互不干扰**。这是“尴尬并行 (Embarrassingly Parallel)”问题，非常适合并行化。

### 高斯-赛德尔迭代 (Gauss-Seidel) - 难以并行

Gauss-Seidel 为了收敛更快，使用了**最新**的值：
$$ V_{i,j}^{(k+1)} = \frac{1}{4} (V_{i-1,j}^{\color{red}{(k+1)}} + V_{i+1,j}^{(k)} + V_{i,j-1}^{\color{red}{(k+1)}} + V_{i,j+1}^{(k)}) $$
注意红色的 $(k+1)$：

- 要计算点 $(i, j)$，你必须先知道 $(i-1, j)$ 的**新值**。
- 要计算 $(i-1, j)$，你必须先知道 $(i-2, j)$ 的**新值**。
- 这形成了一条**依赖链**。核心 B 不能开始工作，直到核心 A 算完它的部分。这导致了串行化。

---

## 3. 破局之法：红黑排序 (Red-Black Ordering)

如何让 Gauss-Seidel 也能并行？数学家想出了一个绝妙的技巧，灵感来自国际象棋棋盘。

我们将网格点分为两类：
- **红点 (Red)**: $i + j$ 是偶数
- **黑点 (Black)**: $i + j$ 是奇数

### 观察
在 2D 网格中，一个红点的四个邻居（上、下、左、右）**全都是黑点**。
一个黑点的四个邻居**全都是红点**。

### 并行策略
我们将一次迭代分为两步：
1.  **第一步**：所有核心同时更新**所有红点**。
    - 此时需要读取邻居（黑点）的值。
    - 黑点的值在这一步是**不变**的（只读）。
    - 所以红点之间**没有依赖**，可以完美并行！
2.  **第二步**：所有核心同时更新**所有黑点**。
    - 此时利用刚刚算好的红点新值。
    - 黑点之间也**没有依赖**。

这就是你在 `solver.py` 中看到的 `_update_checkerboard` 方法的数学原理！它不仅仅是为了好玩，而是为了**解耦数据依赖**，为并行计算铺路。

---

## 4. 真正的并行：区域分解 (Domain Decomposition)

如果我们真的要用 8 个核心（甚至 1000 个核心），我们通常使用**区域分解法**。

### 分治策略

假设有一个 $100 \times 100$ 的网格，我们有 4 个核心。
我们将网格切成 4 块 $50 \times 50$ 的子网格。
- 核心 0 负责左上角
- 核心 1 负责右上角
- ...

### 幽灵区 (Ghost Cells / Halo Regions)
问题来了：核心 0 在计算它的右边缘时，需要核心 1 的左边缘数据。但核心 1 的数据在另一个内存区域（甚至另一台电脑上）。

**解决方案**：
我们在每个子网格周围加一圈“幽灵节点”。
- 核心 0 存储核心 1 的边界副本。
- 每次迭代结束后，核心 0 和核心 1 **通信**，交换边界数据。

这就是超级计算机（如天河、Summit）运行大规模科学模拟的基本模式：**计算 -> 通信 -> 计算 -> 通信**。

---

## 5. 课后思考

在“区域分解”模式下，如果通信（交换边界数据）太慢，会发生什么？
回顾 Amdahl 定律，通信时间属于“串行部分”还是“并行部分”？这对我们设计算法有什么启示？
