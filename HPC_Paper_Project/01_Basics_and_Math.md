# 第一课：并行计算基础与数学原理

## 1. 为什么我们需要并行计算？

在你的 `electrostatic_simulation` 项目中，你可能已经发现，当网格大小 (`size_x`, `size_y`) 变大时，计算时间会显著增加。

假设我们将网格的分辨率提高一倍（例如从 $100 \times 100$ 变成 $200 \times 200$）：
- 网格点数量从 $10,000$ 变成了 $40,000$（增加了 4 倍）。
- 每次迭代需要更新的点数也增加了 4 倍。
- 此外，网格越密，迭代收敛通常需要更多的步数。

这意味着计算量的增长是**超线性**的。单靠提高 CPU 的主频（摩尔定律的放缓）已经无法满足科学计算的需求。我们需要**并行计算**——让多个工人（CPU 核心）同时干活。

## 2. 核心数学推导：阿姆达尔定律 (Amdahl's Law)

这是并行计算中最著名的定律，它告诉我们：**并行化能带来的加速是有极限的**。

### 定义

假设一个程序由两部分组成：
1. **串行部分 (Serial Part)**：必须按顺序执行，无法并行化。比例为 $1-P$。
2. **并行部分 (Parallel Part)**：可以完美地分配给多个处理器同时执行。比例为 $P$。

假设总工作量为 $1$。
在单处理器上，总执行时间 $T(1) = 1$。

### 推导
现在我们有 $N$ 个处理器。
- 串行部分的时间保持不变：$T_{serial} = 1 - P$
- 并行部分的时间被 $N$ 个处理器分摊：$T_{parallel} = \frac{P}{N}$

那么，并行后的总执行时间 $T(N)$ 为：
$$ T(N) = (1 - P) + \frac{P}{N} $$

**加速比 (Speedup)** 定义为单处理器时间与多处理器时间之比：
$$ S(N) = \frac{T(1)}{T(N)} = \frac{1}{(1 - P) + \frac{P}{N}} $$

### 极限分析 (Limit Analysis)
当处理器数量 $N$ 趋向于无穷大 ($N \to \infty$) 时，$\frac{P}{N} \to 0$。
此时加速比趋向于一个常数极限：
$$ \lim_{N \to \infty} S(N) = \frac{1}{1 - P} $$

### 深刻含义
这个公式非常残酷。
- 如果你的程序中只有 **5%** 的代码是必须串行的 ($P = 0.95$)，那么 $1-P = 0.05$。
- 即使你有 **无限多** 的 CPU，$S(\infty) = \frac{1}{0.05} = 20$。
- 你永远无法获得超过 20 倍的加速。

**结论**：并行计算的关键不仅仅是增加 CPU 核心，更重要的是**减小串行部分的比例**。

---

## 3. 结合你的项目：`solver.py` 的复杂度分析

让我们看看你的 `LaplaceSolver.solve` 方法。

### 算法逻辑

你使用的是迭代法（Jacobi 或 SOR）求解线性方程组 $Ax=b$（这里是离散化的拉普拉斯方程）。

对于 $N_x \times N_y$ 的网格，总节点数 $N = N_x \times N_y$。

在 `solver.py` 中：
```python
# 核心更新逻辑 (Jacobi)
V_neighbors = 0.25 * (V_old[1:-1, 0:-2] +  # 左
                      V_old[1:-1, 2:] +    # 右
                      V_old[0:-2, 1:-1] +  # 上
                      V_old[2:, 1:-1])     # 下
```

### 时间复杂度
1.  **单次迭代**：你需要遍历网格内部的每一个点。操作次数与 $N$ 成正比。复杂度为 $O(N)$。
2.  **收敛次数**：对于拉普拉斯方程，迭代法的收敛速度与网格点数有关。通常，Jacobi 方法需要的迭代次数大致与 $N$ 成正比（或者说与网格边长的平方成正比）。
3.  **总复杂度**：$O(N) \times O(N) = O(N^2)$。

如果 $N$ 增加 10 倍，计算时间可能会增加 100 倍！

### 空间复杂度
你需要存储电势矩阵 `V` 和边界标记 `boundary_mask`。
空间复杂度为 $O(N)$。

### 并行性分析
在你的代码中，`V_neighbors` 的计算是**高度并行**的。
- 计算点 $(i, j)$ 的新值只需要它的四个邻居 $(i-1, j), (i+1, j), (i, j-1), (i, j+1)$ 的**旧值**。
- 这意味着，点 $(10, 10)$ 的计算和点 $(20, 20)$ 的计算**互不干扰**。
- 我们可以让 CPU 核心 1 计算左半部分网格，核心 2 计算右半部分网格。

这就是为什么你的项目非常适合作为并行计算的案例！

---

## 4. 课后思考

在 `solver.py` 的 `solve` 函数中，有一行代码是：
```python
# 计算误差 (最大变化量)
diff = np.abs(self.V - V_old).max()
```
请思考：这行代码是“并行部分”还是“串行部分”？
提示：为了得到**全局**的最大值，所有并行的工人都需要把它们的结果汇总起来。这在并行计算中被称为 **Reduction (归约)** 操作。
